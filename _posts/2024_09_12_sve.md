---
layout: post
title: Genetic algorithm for Register Allocation
subtitle: Experiment that gave great insights
tags: [register allocation, LSRA, RyuJIT]
---

Engineering SVE in .NET

## Introduction

128-bits is 16B and 256-bits are 32B

## What is SVE?

SVE an acronym for Scalable Vector Extension is the Arm processor feature that lets you program on vector length that is hardware defined and developers do not have to worry about it. Once the code is written, it doesn't need be recompiled for the future version of hardware that can expand the vector length. There are numerous articles and blog posts that describes SVE. 

Explain difference between non-streaming and streaming mode SVE.

## Predicates

diagrams of predicate register and some operations



## Backend

To add a given ISA in a compiler, there is a pre-requisite to add support for the new instructions so that compiler can generate them. There are lot of details that goes in for implementing instructions. Starting with the lowest level, the opcodes of instrutions need to be added in the codebase, along with the corresponding pneumonic names. Many instructions comes with different versions having different number of operands, size of data they handle or various register requirements. All these finer details need to be fed in an easy to understand lookup table. Next, the code generation infrastructure need to be updated to make sure that the new instructions can be emitted in relevant places. Higher up, if there are any new registers introduced as per of the instruction, they need to be added in the register allocation. Every ISA defines its own Application Binary Interface (ABI) that specifies what happens to the state of registers at the sub-routine boundary and whose responsibility it is to save and restore the registers. In below sections, we will look through the work we have done in each of these phases to support SVE.

### SVE encoding

In compiler literature, "instruction encodes" refers to the opcodes of each instruction that are found in the Architecture manual. Compilers usually embedded these opcodes in some kind of lookup table such that key is a pneumonic name (or instruction name that is easy to understand by the developer) and value is the opcode of that instruction. The code generator knows which instruction to emit and it invokes the encoder to output the corresponding opcodes in the final code buffer.

<< TODO: snapshot of instruction encodes of SETFFR >>

In above screenshot, taken from Arm manual, the opcode of `setffr` instruction can be seen as `0x252C9000`. 

Now, lets look at step by step on how the opcodes that can be found in the instruction manual get it through the compiler codebase.

1. The opcodes of new instructions has to be added in our codebase, such that the encoder and code generator has access to it. This can be seen in [instrsarm64sve.h](TODO) file as shown below.

<< TODO: snapshot of instrarm64sve.h for SETFFR>>

Next, there are several code paths that need to be updated in order to enable the instruction that got added in above lookup table.

2. For a code generator, to emit the any instruction, there is a giant `switch-case` against the instruction to be emitted. Depending on the instruction, the individual `case` statement calls the encoder to perform the encoding. The new instruction need to be added in such `switch-case`.

3. If an instruction has multiple formats, we need to update the code paths, to include the formats of the newly added instruction. 

4. There are sanity checks that are done while emitting each instruction to make sure that the instruction we are emitting has right set of registers, the data/vector size embedded in the opcode of the instruction is relevant, the immediates present in the instruction is within the allowable range, etc. All these codepaths need to get updated for any new instruction we add. 

5. For a disassembler, to display the pneumonic names of the instruction for a developer, we need to update the codepaths to include the new instruction to display them appropriately.

6. If we want to calculate the performance characteristics like latency and throughput of the newly added instruction, we need to update those paths.

7. Lastly, if there is a provision to unit test the instruction, we need to add unit tests for the new instructions.

What we can infer is for every new instruction a compiler adds support for, there are handful of places that needs to be updated to make sure the new instruction is completely enabled and functional. For SVE, we had to add 1123 new instructions. Yes, that is "One Thousand, One Hundred and Twenty Three" instructions. For an engineer to add support for a single instruction, from inspecting the opcodes in the Arm Manual, to understand the opcodes, to typing in the opcodes, to updating all the code paths, and all the places I described above, up to the point they can validate the instruction with unit test, it will at least take 3~4 hours to complete the task. For 1123 instructions, that is 561 work days.


If we count number of places that need

We evaluate the performance chara

The new instruction that we added  


encodings of new instructions and plumbing the creating of those instructions through out the code base of a compiler. This is not a big task for handful of instructions. However, for SVE, we set an ambitious goal of implementing 1123 instructions.

tool, formatting, instruction names, encoding

### Register allocation to handle more than 64 registers

### prolog and epilog handling

### ABI

## Frontend

### SVE APIs

### Vector<T>

### VectorToMask and MaskToVector conversions

### Conditional Select

### Delay free registers

### movprfx instruction

### Predicated, Unpredicated, both

## FFR register

## Diagnostics

## Context switches

## Debugging

## Testing 

unit test

stress test running locally

### Partners

## Hardware availability

Currently SVE is available in very limited hardwares, but vendors are pushing towards introducing SVE. Microsoft Azure recently released Arm offering of Cobalt 100 that has non-streaming SVE feature. Amazon's AWS has Graviton 3 that comes with 2 x 16B VL, Graviron 4 comes with 16B vector length, Apple's M4 has 64B vector length and supports streaming SVE and SME features. And there is Fijitsu's super computer that offers SVE 64B VL.

### Future

- streaming SVE and SME
- True VL agnostic


### References

good references that explain SVE features in details along with the coding examples.