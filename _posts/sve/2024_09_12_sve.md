---
layout: post
title: Genetic algorithm for Register Allocation
subtitle: Experiment that gave great insights
tags: [register allocation, LSRA, RyuJIT]
---

Engineering SVE in .NET

## Introduction

128-bits is 16B and 256-bits are 32B

lot of technical information along with SVE design, etc.

## What is SVE?

SVE an acronym for Scalable Vector Extension is the Arm processor feature that lets you program on vector length that is hardware defined and developers do not have to worry about it. Once the code is written, it doesn't need be recompiled for the future version of hardware that can expand the vector length. There are numerous articles and blog posts that describes SVE. 

Explain difference between non-streaming and streaming mode SVE.

## Predicates

diagrams of predicate register and some operations



## Backend

To include an ISA in a compiler, there is a pre-requisite to add support for the new instructions the ISA offers, so that compiler can generate them. There are lot of details that goes in for implementing instructions. Starting with the lowest level, the opcodes of instrutions need to be added in the codebase, along with the corresponding pneumonic names. Many instructions comes with different versions having different number of operands, size of data they handle or various register requirements. All these finer details need to be fed in an easy to understand lookup table. Next, the code generation infrastructure need to be updated to make sure that the new instructions can be emitted in relevant places. Higher up, if there are any new registers introduced as per of the instruction, they need to be added in the register allocation. Every ISA defines its own Application Binary Interface (ABI) that specifies what happens to the state of registers at the sub-routine boundary and whose responsibility it is to save and restore the registers. In below sections, we will look through the work we have done in each of these phases to support SVE.

### SVE encoding

In compiler literature, "instruction encodes" refers to the opcodes of each instruction that are found in the Architecture manual. Compilers usually embedded these opcodes in some kind of lookup table such that key is a pneumonic name (or instruction name that is easy to understand by the developer) and value is the opcode of that instruction. The code generator knows which instruction to emit and it invokes the encoder to output the corresponding opcodes in the final code buffer.

![alt text](image-4.png)

In above screenshot, taken from Arm manual, the opcode of `setffr` instruction can be seen as `0x252C9000`. 

Now, lets look at step by step on how the opcodes that are found in the instruction manual get it through the compiler codebase.

1. The opcodes of new instructions has to be added in our codebase, such that the encoder and code generator has access to it.

TODO-START: Do not include
 This can be seen in [instrsarm64sve.h](TODO) file as shown below.

<< TODO: snapshot of instrarm64sve.h for SETFFR>>

Next, there are several code paths that need to be updated in order to enable the instruction that got added in above lookup table.

TODO-END: Do not include

2. For a code generator, to emit the any instruction, there is a giant `switch-case` against the instruction to be emitted. Depending on the instruction, the individual `case` statement calls the encoder to perform the encoding. The new instruction need to be added in such `switch-case`.

3. If an instruction has multiple formats, we need to update the code paths, to include the formats of the newly added instruction. 

4. There are sanity checks that are done while emitting each instruction to make sure that the instruction we are emitting has right set of registers, the data/vector size embedded in the opcode of the instruction is relevant, the immediates present in the instruction is within the allowable range, etc. All these codepaths need to get updated for any new instruction we add. 

5. For a disassembler, to display the pneumonic names of the instruction for a developer, we need to update the codepaths to include the new instruction to display them appropriately.

6. If we want to calculate the performance characteristics like latency and throughput of the newly added instruction, we need to update those paths.

7. Lastly, if there is a provision to unit test the instruction, we need to add unit tests for the new instructions.

What we can infer is for every new instruction a compiler adds support for, there are handful of places that needs to be updated to make sure the new instruction is completely enabled and functional. For SVE, we had to add 1123 new instructions. Yes, that is "One Thousand, One Hundred and Twenty Three" instructions. For an engineer to add support for a single instruction, from inspecting the opcodes in the Arm Manual, to understand the opcodes, to typing in the opcodes, to updating all the code paths, and all the places I described above, up to the point they can validate the instruction with unit test, it will at least take 3~4 hours to complete the task. For 1123 instructions, that is 561 work days, or little over 2 years of work for a single engineer.

With those timelines and estimate, there was no one we could have finished adding all the instructions, let alone exposing the intrinsics in .NET APIs layer. We realized that most of the code I mentioned above thatw was required to light up an instruction was very similar. All it needed was to translate an instruction details presented in the Arm architecture manual into the C++ code that can fit in RyuJIT's codebase. We started exploring options of auto generating some portion of the C++ code. To do that, we needed some utility that will scan pdf documents (Arm manual that is in pdf format) and extract out important information from it. However, we did not have such tool at our exposure or expertise to write a custom utility tool that knows how to parse the pdf pages. 

#### SVE encoding auto-generated C++ code

Arm Ltd. had [xml version](https://developer.arm.com/Architectures/A-Profile%20Architecture#Software-Download) of all their instruction set, which was much easier to write a parser for. We spent 3~4 weeks to write a tool in C# (of course) that parsed the xml files containing instruction data and generating various versions of C++ code that was needed at several places in our codebase. If you see [SveEncodingFiles](https://github.com/kunalspathak/SveEncodingFiles), the tool produced more than 17K lines of C++ code spread across 15 files. Imagine what a hard task it would be for an engineer having to type all this code by hand! The tool proved to be a great value add for our team and was worth pursuing.

When it came to implementation, all that an engineer had to do was copy the auto-generated code for each instruction from various files and paste it at the right place in our codebase. We distributed the instructions among 3 engineers. As you must have guessed, we also auto-generated the [distribution of instructions](https://github.com/kunalspathak/SveEncodingFiles/blob/main/assignments.md) among engineers. The engineers were able to implement all the instructions without having to worry about ay dependencies on each other or complicated merge conflicts during development. We finished adding all the 1123 encodings in little over 3 months. Hand writing the code for encoding would have took almost 9 months for 3 engineers. That was a total saving of 6 months for 3 engineers, or 18 man-months!

While there were lot of challenges in understanding the xml files semantics, how they are interconnected to other instruction files and writing parsing tools to make sure that we do not interpret the data incorrectly, it is worth its own blog post. Here, I will just walk you through few auto-generated files to highlight some of the key design of the tool.

1. [instrsarm64sve.h](https://github.com/kunalspathak/SveEncodingFiles/blob/main/instrsarm64_sve.h): All the instructions that RyuJIT offers are stored in a table. Each instruction can have several different formats by which they operate, depending on the size of vector, size of data, size of individual elements, those containing immediate operand and so forth. For e.g., `ld1sb` instruction's entry in `Fig 1.` has 6 different formats (as seen in [1](https://docsmirror.github.io/A64/2023-06/ld1sb_z_p_bi.html), [2](https://docsmirror.github.io/A64/2023-06/ld1sb_z_p_br.html), [3](https://docsmirror.github.io/A64/2023-06/ld1sb_z_p_bz.html) and [4](https://docsmirror.github.io/A64/2023-06/ld1sb_z_p_ai.html)). Every instruction format has the normalized opcodes in binary and hexadecimal formats. In the first instruction format of `Fig. 1`, the binary representation comes from [the Arm manual](https://docsmirror.github.io/A64/2023-06/ld1b_z_p_bz.html) seen in `Fig 2.`. The normalized version in our codebase basically has `0` at all the bit positions that encodes the information during code generation. One of the example is registers used in an instruction. If you see the binary representation, there are characters like `g`, `n` and `t` in them. Those positions are filled up when register corresponding to `g`, `n` and `t` are known during code generation. Without the tool, it would have been very time consuming task to translate the information in Arm manual (from `Fig 2.`) into the C++ code (in `Fig 1.`). 

   Other critical information that the tool helped generate for us was the format names. In `Fig 1.`, all instruction formats have names that starts with `SVE_*`. All instruction formats (of different instructions) that share same "normalized" binary/hexadecimal encoding gets the same format name. The rational behind this design is that all the formats having same "normalized" encoding, would get encoded during code generation in similar way. By grouping all such instruction formats with a format name that share similar encoding logic, we easily can share the C++ code needed to handle those formats (as you will see further). Now, imagine if each engineer start implementing the instructions assigned to them, it will be very challenging and difficult to co-ordinate to see if the format they are working on already exists and if not, the nomenclature they should use for the format name. By letting the tool do the heavy lifting for us, we embedded the logic of grouping various instruction formats and naming them with consistent naming conventions in the tool itself. As a result, the engineer was not burdened with this thinking of grouping similar formats.


   ![alt text](image-2.png)

   <p style="text-align: center;">Fig 1. Instruction encoding formats for "ld1sb"</p>

   ![alt text](image-3.png)

   <p style="text-align: center;">Fig 2. Arm manual's encoding entry for "ld1sb"</p>

2. [emitfmtsarm64sve.h](https://github.com/kunalspathak/SveEncodingFiles/blob/main/emitfmtsarm64_sve.h): Talking about the instruction format names, we also have a lookup table for individual format names along with the format it represents and brief description. From the Arm manual, we were able to easily extract this information and generate the lookup table with the new SVE format names. The nomenclature that we came up with was `SVE_XX_AB`, where `XX` is just alphabetical in order starting with `AA`, `AB` and so forth. `A` represents the number of register the format operates on, and `B` is another alphabetical order if there are slight variations from `SVE_XX_A` format. 

   ![alt text](image-5.png)

   <p style="text-align: center;">Fig 3. List of instruction format names</p>


3. Instruction to format mapping ([1](https://github.com/kunalspathak/SveEncodingFiles/blob/main/emitIns_R_I_sve.cpp), [2](https://github.com/kunalspathak/SveEncodingFiles/blob/main/emitIns_R_R_I_sve.cpp), [3](https://github.com/kunalspathak/SveEncodingFiles/blob/main/emitIns_R_R_R_I_sve.cpp), [4](https://github.com/kunalspathak/SveEncodingFiles/blob/main/emitIns_R_R_R_R_I_sve.cpp), [5](https://github.com/kunalspathak/SveEncodingFiles/blob/main/emitIns_R_R_R_R_sve.cpp), [6](https://github.com/kunalspathak/SveEncodingFiles/blob/main/emitIns_R_R_R_sve.cpp), [7](https://github.com/kunalspathak/SveEncodingFiles/blob/main/emitIns_R_R_sve.cpp), [8](https://github.com/kunalspathak/SveEncodingFiles/blob/main/emitIns_R_sve.cpp)): Since the auto generator tool already had the mapping of instruction format names to the instruction, we also leveraged it to generate reverse mapping needed to select the instruction format, depending on the instruction we want to emit.

   ![alt text](image-10.png)
    <p style="text-align: center;">Fig TODO. Instruction -> format mapping</p>

3. [emitOutputInstr.cpp](https://github.com/kunalspathak/SveEncodingFiles/blob/main/emitOutputInstr_sve.cpp), [dispHelper.cpp](https://github.com/kunalspathak/SveEncodingFiles/blob/main/emitDispInsHelp_sve.cpp), [sanityCheck.cpp](https://github.com/kunalspathak/SveEncodingFiles/blob/main/emitInsSanityCheck_sve.cpp): The next important piece of code the tool helped us generate was a huge switch/case, where depending on individual instruction format names, there is a common logic of handling them at various places in our codebase.

   In `Fig 4.` below, there is an encoding logic for `IF_SVE_BJ_2A` and following cases. It starts with the encodings we have in `instrsarm64sve.h`. Then, we encode the register represented by `nnnnn`, followed by the register represented by `ddddd` and then the element size `xx` of the instruction we are emitting. Because of the virtue of having all the manual's data handy, the tool was able to generate nice comments and other finer details that are easy to miss, if done manually.

   ![alt text](image-6.png)
   <p style="text-align: center;">Fig 4. Encoding of instruction formats</p>


   In a similar fashion, the tool generated all the relevant code necessary to display the disassembly of each instruction as seen in `Fig 5.` below.

   ![alt text](image-7.png)
    <p style="text-align: center;">Fig 5. Displaying disassembly</p>

   Lastly, to ensure that the instruction contains correct information like register, data size, etc. embedded, we do a round of sanity check and new checks were added by the tool for the SVE instructions as seen below.

   ![alt text](image-8.png)
    <p style="text-align: center;">Fig 6. Sanity checks</p>


4. [PerfScore.cpp](https://github.com/kunalspathak/SveEncodingFiles/blob/main/emitPerfScore_sve.cpp): For our debugging purpose, we emit the latency and throughput information of the entire method to understand how fast or slow the method would be. The latency and throughput information of individual instructions is taken from the Architecture Manuals and is embedded in our codebase. For new instructions, it would have been again tedious to find it in the manual and put it in our codebase. The tool helped to come up with
[perfscore.md](https://github.com/kunalspathak/SveEncodingFiles/blob/main/perfscore.md) that contained all the information needed for this purpose. As seen in `Fig todo.`, depending on instruction format and specific instruction, we embedded the perfscore information in our codebase.


   ![alt text](image-11.png)
    <p style="text-align: center;">Fig todo. Perfscore calculations</p>

To read more details, you can refer to the [dotnet/runtime#94549](https://github.com/dotnet/runtime/issues/94549) that lists all the encodings we added as well as links to the PRs that implemented the instructions.

![alt text](image-12.png)
<p style="text-align: center;">Fig todo. Sve encodings progress</p>

### Register allocation to handle more than 64 registers

The next important topic to talk about is support in register allocator.

### prolog and epilog handling

### ABI

## Frontend

### SVE APIs

### Vector<T>

### VectorToMask and MaskToVector conversions

### Conditional Select

### Delay free registers

### movprfx instruction

### Predicated, Unpredicated, both

## FFR register

## Diagnostics

## Context switches

## Debugging

## Testing 

unit test

stress test running locally

## Partners

Acknowledgement:
 - Alan Haywards
 - Aman Asif Khalid
 - Kunal Pathak
 - Sebastin
 - Arm engineer who was present for API implementation??
 - Swapnil
 - Will Smith

## Hardware availability

Currently SVE is available in very limited hardwares, but vendors are pushing towards introducing SVE. Microsoft Azure recently released Arm offering of Cobalt 100 that has non-streaming SVE feature. Amazon's AWS has Graviton 3 that comes with 2 x 16B VL, Graviron 4 comes with 16B vector length, Apple's M4 has 64B vector length and supports streaming SVE and SME features. And there is Fijitsu's super computer that offers SVE 64B VL.


### Future

- streaming SVE and SME
- True VL agnostic


### References

- https://developer.arm.com/Architectures/A-Profile%20Architecture#Software-Download

good references that explain SVE features in details along with the coding examples.